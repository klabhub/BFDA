---
title: "Bayes factor design analysis: Manual for the BFDA package"
author: "Felix Schönbrodt, Angelika Stefan"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_float: true
---

This document demonstrates how to do a design analysis (aka. power analysis) for studies which use Bayes factors as index of evidence.
For more details about Bayes Factor Design Analysis (BFDA), see our papers:

> Schönbrodt, F. D. & Wagenmakers, E.-J. (2017). Bayes Factor Design Analysis: Planning for compelling evidence. *Psychonomic Bulletin & Review*. doi:10.3758/s13423-017-1230-y. [[PDF](https://osf.io/d4dcu)][[OSF project with reproducible code](https://osf.io/v7yxp/)]

> Stefan, A. M., Gronau, Q. F., Schönbrodt, F. D., & Wagenmakers, E. (2018). A Tutorial on Bayes Factor Design Analysis with Informed Priors. [PsyArXiv Preprint](https://doi.org/10.31234/osf.io/aqr79)

If you use this package to compute and report your design analysis, please cite it as:

> Schönbrodt, F. D. & Stefan, A. M. (2018). BFDA: An R package for Bayes factor design analysis (version 0.3). Retrieved from https://github.com/nicebread/BFDA

Please note that this package is still a development version; take the results with a grain of salt.


```{r setup, include=FALSE}
	library(tint)
	knitr::opts_chunk$set(cache=TRUE, warnings = FALSE, messages=FALSE)
	# load all functions
	devtools::load_all("../package")
```

# Installation #

The BFDA package is not on CRAN yet, but you can install the development version from Github:

```{r eval=FALSE}
library(devtools)
install_github("nicebread/BFDA", subdir="package")
```


# The general workflow #

1. Simulate many hypothetical studies, both under H1 and under H0, using the function `BFDA.sim`
2. Analyze the simulated studies, using the function `BFDA.analyze`
3. Plot the simulated studies (`plot`, `SSD`, `evDens`)
4. Tune your design in a way that you achieve the desired goals with adequate probability (`SSD`)

To summarize, the general workflow is (here shown without parameters; these are discussed later):

```{r eval=FALSE}
sim.H1 <- BFDA.sim(expected.ES = 0.5, ...)
sim.H0 <- BFDA.sim(expected.ES = 0, ...)

BFDA.analyze(sim.H1)
BFDA.analyze(sim.H0)

plot(sim.H1)
plot(sim.H0)

SSD(sim.H1)
SSD(sim.H0)
```


## 1. Simulating hypothetical studies for a prospective design analysis

As we do not know in advance whether H1 or H0 provide a better predictive performance of real world data, we want to evaluate the performance of a design under *both* hypotheses. Hence, we have to simulate a "H1 world" and a "H0 world":

```{r sim, cache=TRUE, results='hide'}
sim.H1 <- BFDA.sim(expected.ES=0.5, type="t.between", prior=list("Cauchy", list(prior.location=0, prior.scale=sqrt(2)/2)), n.min=20, n.max=100, alternative="greater", boundary=Inf, B=1000, verbose=TRUE, cores=4, stepsize = 10)

sim.H0 <- BFDA.sim(expected.ES=0, type="t.between", prior=list("Cauchy", list(prior.location=0, prior.scale=sqrt(2)/2)), n.min=20, n.max=100, alternative="greater", boundary=Inf, B=1000, verbose=TRUE, cores=4, stepsize = 10)
```

Let's go through the most important parameters (for a full list of options, see `?BFDA.sim`):

  - `expected.ES`: The assumed effect size (ES). In classical power analysis, this is a fixed number. Here, you can also provide a vector, which quantifies the uncertainty about the true ES. For example:       `expected.ES=rnorm(100000, 0.5, 0.1)`. If a vector is provided, a new ES is drawn from this vector for  each simulated study. The **metric** for `expected.ES` depends on the type of design (see next bullet  point):

    - `type = "t.between"` or `type = "t.paired"`: expected.ES has to be provided as Cohen's *d*
    
    - `type = "correlation"`: expected.ES has to be provided as correlation
    
  - `type`: Type of design. Currently, 3 designs are implemented: A between-group t-test ("t.between"), a paired t-test ("t.paired"), and correlations ("correlation")

  - `prior`: This argument specifies the prior distribution under the alternative hypothesis. It consists of a list with two elements: The first element is a character vector which specifies the type of the prior distribution. The second element is a list which contains the hyperparameters of the prior distribution. For example, the prior distribution for t-tests could be defined as `prior = list("Cauchy", prior.location = 0, prior.scale = sqrt(2)/2))` which is the default prior suggested in the *BayesFactor* R package. The choice of prior distributions depends on the type of design (see next bullet point)

    - `type = "t.between"` or `type = "t.paired"`: There are 3 distribution types you can choose from
        - A Cauchy distribution (`"Cauchy"`) with the hyperparameters `prior.location` (non-centrality parameter) and `prior.scale` (scale parameter)
        
        - A t distribution (`"t"`) with the hyperparameters `prior.location`, (non-centrality parameter) `prior.scale`, (scale parameter) and `prior.df`(degrees of freedom)
        - A normal distribution (`"normal"`) with the hyperparameters `prior.mean` (mean) and `prior.variance` (variance)
        
    - `type = "correlation"`: The prior distribution on the correlation is a stretched beta prior (`"stretchedbeta"`) with the hyperparameter $\kappa$ (`prior.kappa`). The stretched beta distribution is a beta distribution with the parameters $\alpha = \beta = 1/ \kappa$ whose domain is extended from [0, 1] to [-1, 1].
    
  - `n.min` and `n.max`: The initial sample size and the maximum sample size that is tested in the sequential procedure.

  - `alternative`: Either "two.sided" for two-sided tests, "greater" for a positive directional alternative hypothesis (the effect size is greater than zero), or "less" for a negative directional alternative hypothesis (the effect size is smaller than zero).
- `B`: Number of simulated studies. Aim for B >= 10,000 for stable results (in this document we use B=1000 to save some computation time).

  - `cores`: Multicore support. Add as many cores as you have to speed up computations.

The simulations of the "H1 world" and a "H0 world" should have the same parameters (type, prior, alternative, rscale, boundary, n.min, n.max, B) except the `expected.ES` (in the actual data analysis, we will apply the same test to the data set, regardless whether data came from H0 or H1 (what we don't know anyway.)).

The BFDA uses the informed t-test functions by [Gronau, Ly, & Wagenmakers (2017)](https://arxiv.org/abs/1704.02479) to compute the between and paired t-test. By default, it uses a central Cauchy distribution with a scale parameter of sqrt(2)/2 as a prior on effect size under H1. For correlations, it uses the source code of the statistics software JASP [(available on Github)](https://github.com/jasp-stats/jasp-desktop/blob/development/JASP-Engine/JASP/R/correlationbayesian.R) which is based on a paper by [Ly, Verhagen & Wagenmakers (2016)](https://www.sciencedirect.com/science/article/pii/S0022249615000383) and a paper by [Ly, Marsman, & Wagenmakers](https://onlinelibrary.wiley.com/doi/full/10.1111/stan.12111). By default, it uses a stretched beta prior on the effect size under H1 with a $\kappa$ parameter of 1, which is equivalent to a uniform prior distribution over the possible correlations.

By default, a full sequential design without evidential stopping threshold is simulated. This means that samples are drawn in a sequential process (n.min + 1 + 1 + ...) until the maximum sample size is reached and the hypothesis test is conducted at each stage of this sequential process. The process does not stop when a Bayes factor boundary is reached (e.g., BF(accumulated sample) > 6 or BF(accumulated sample) < 1/6), but when n.max is reached. This allows to extract the results of sequential BFDA procedures with arbitrary thresholds and a maximum N of n.max. With the arguments `design` and `n.max` it is possible to change the procedure to a fixed-N BFDA (e.g., `design="fixed.n", n.max=200` for a fixed-N design with 200 observations) or an open-ended sequential procedure (e.g., `design="sequential", n.max = Inf`).

## 2. Analyze the simulations ##

Next, we can retrieve summary statistics from our simulations. For these summaries, we can define evidential thresholds ("How"), minimal and maximal sample sizes

For example, we can get the operational characteristics of a **fixed-n design**:

```{r analyze}
BFDA.analyze(sim.H1, design="fixed", n=50, boundary=6)
BFDA.analyze(sim.H0, design="fixed", n=50, boundary=6)
```

And for a **sequential design**:

```{r analyze2}
BFDA.analyze(sim.H1, design="sequential", n.min=20, n.max=300, boundary=10)
```
Here, all studies hit a boundary before n.max is reached. If we reduce n.max, some studies do not reach an evidential threshold:

```{r analyze3}
BFDA.analyze(sim.H1, design="sequential", n.min=20, n.max=100, boundary=10)
```

## 3. Plot the design analysis

### Compare distributions of BFs for a fixed *n*

```{r evDens, warning=FALSE}
evDens(BFDA.H1=sim.H1, BFDA.H0=sim.H0, n=50, boundary=c(1/6, 6), xlim=c(1/11, 31))
```


### Open-ended sequential design

Under H1:
```{r SBF1, warning=FALSE}
plot(sim.H1, n.min=20, boundary=c(1/6, 6))
```

Under H0:
```{r SBF0, warning=FALSE}
plot(sim.H0, n.min=20, boundary=c(1/6, 6))
```


### Sequential design with n.max and asymmetric boundaries

Under H1:
```{r SBF_nmax, warning=FALSE}
plot(sim.H1, n.min=20, n.max=80, boundary=c(1/5, 10))
```

## 4. Sample Size Determination (SSD) ##

What sample size do you need to ensure, say, 80% probability that a study design finds an effect of size, say, 0.5 with a BF >= 10?

```{r SSD1, warning=FALSE}
SSD(sim.H1, power=.80, boundary=c(1/10, 10))
```

What sample size do I need to have less than 2% of studies with a false positive error, if I set the boundary to 2?
**Note: A BF threshold of 2 should never be used! Aim for a BF of at least 5. This is for didactical purposes only!**

```{r SSD2, warning=FALSE}
SSD(sim.H0, alpha=.02, boundary=c(1/2, 2))
```

Note: The SSD function automatically detects whether a H1 or a H0 simulation is analyzed. Also note that these numbers of necessary sample sizes are based on simulations and can differ between runs (see the rugged border between the shaded areas in the plot). The larger the number `B` of simulations, the less variable are these estimates.


# Paired t-test: A complete example #

The effect size metric is d_z (standardized difference scores).

```{r paired.t, warning=FALSE}
#devtools::install_github("nicebread/BFDA", subdir="package")
#library(BFDA)

# do a sequential design analysis
s1 <- BFDA.sim(expected.ES=0.4, prior=list("t", list(prior.location=0, prior.scale=sqrt(2)/2, prior.df=1)), n.min=50, stepsize=5, n.max=300, type="t.paired", design="sequential", alternative="greater", B=1000, cores=4, verbose=FALSE)
s0 <- BFDA.sim(expected.ES=0, prior=list("t", list(prior.location=0, prior.scale=sqrt(2)/2, prior.df=1)), n.min=50, stepsize=5, n.max=300, type="t.paired", design="sequential", alternative="greater", B=1000, cores=4, verbose=FALSE)

# if no n.min and n.max is provided in the `BFDA.analyze` function, the values from the simulation are taken
BFDA.analyze(s1, design="sequential", boundary=10)
BFDA.analyze(s0, design="sequential", boundary=10)

BFDA.analyze(s1, design="sequential", boundary=6)
BFDA.analyze(s0, design="sequential", boundary=6)

plot(s1)
```



# Correlation: A complete example #

The correlation BF implemented in the BFDA package uses a stretched beta prior distribution, as described in:

Wagenmakers, E. J., Verhagen, J., & Ly, A. (2016). How to quantify the evidence for the absence of a correlation. *Behavior Research Methods*, 1–14. http://doi.org/10.3758/s13428-015-0593-0

Here, the correlation is first rescaled to lie between 0 and 1, and then a beta distribution with the parameters $\alpha = \beta = 1/\kappa$ is assigned to it. Then, the beta distribution is transformed back to the (−1, 1) scale and the Bayes factors are calculated as a function of $\kappa$. When $\kappa = 1$, this corresponds to a uniform prior on the correlation coefficient, as in Jeffreys's default analysis. When $\kappa \rightarrow 0$, H1 becomes indistinguishable from H0 and consequently the Bayes factor is 1. Values of $\kappa$ in between 0 and $\infty$ define an continuous range of different alternative hypotheses that represent different beliefs about the extent to which large values for the correlation are plausible.

The kappa parameter which can be passed to the BFDA.sim function as part of the "prior" argument, corresponds to the "beta prior width" in JASP. Here are some plots for different settings of kappa for the two-sided case:

```{r corr_kappa_prior_2_plots, cache=TRUE, results='hide'}
rho <- seq(-1, 1, by=.01)

par(mfrow=c(2, 3))
plot(rho, BFDA:::.priorRho(rho, kappa=1),    main=bquote(kappa*" = 1"),    ylim=c(0, 2.4), type="l", xlab="rho", ylab="Plausibility")
plot(rho, BFDA:::.priorRho(rho, kappa=1.5),  main=bquote(kappa*" = 1.5"),  ylim=c(0, 2.4), type="l", xlab="rho", ylab="Plausibility")
plot(rho, BFDA:::.priorRho(rho, kappa=2),    main=bquote(kappa*" = 2"),    ylim=c(0, 2.4), type="l", xlab="rho", ylab="Plausibility")
plot(rho, BFDA:::.priorRho(rho, kappa=3),    main=bquote(kappa*" = 3"),    ylim=c(0, 2.4), type="l", xlab="rho", ylab="Plausibility")
plot(rho, BFDA:::.priorRho(rho, kappa=0.75), main=bquote(kappa*" = 0.75"), ylim=c(0, 2.4), type="l", xlab="rho", ylab="Plausibility")
plot(rho, BFDA:::.priorRho(rho, kappa=0.001),  main=bquote(kappa*" = 0.001"),  ylim=c(0, 2.4), type="l", xlab="rho", ylab="Plausibility")
```

Here are some plots for different settings of kappa for the one-sided case with a positive directional hypothesis:

```{r corr_kappa_prior_1_plots, cache=TRUE, results='hide'}
rho <- seq(0, 1, by=.01)

par(mfrow=c(2, 3))
plot(rho, BFDA:::.priorRhoPlus(rho, kappa=1),    main=bquote(kappa*" = 1"),    ylim=c(0, 4.2), type="l", xlab="rho", ylab="Plausibility")
plot(rho, BFDA:::.priorRhoPlus(rho, kappa=1.5),  main=bquote(kappa*" = 1.5"),  ylim=c(0, 4.2), type="l", xlab="rho", ylab="Plausibility")
plot(rho, BFDA:::.priorRhoPlus(rho, kappa=2),    main=bquote(kappa*" = 2"),    ylim=c(0, 4.2), type="l", xlab="rho", ylab="Plausibility")
plot(rho, BFDA:::.priorRhoPlus(rho, kappa=3),    main=bquote(kappa*" = 3"),    ylim=c(0, 4.2), type="l", xlab="rho", ylab="Plausibility")
plot(rho, BFDA:::.priorRhoPlus(rho, kappa=0.75), main=bquote(kappa*" = 0.75"), ylim=c(0, 4.2), type="l", xlab="rho", ylab="Plausibility")
plot(rho, BFDA:::.priorRhoPlus(rho, kappa=0.001),  main=bquote(kappa*" = 0.001"),  ylim=c(0, 4.2), type="l", xlab="rho", ylab="Plausibility")
```


Here's a complete walkthrough for a one-sided (positive directional) correlation BF design analysis, which places prior weight on smaller effect sizes (kappa = 2):

```{r correlation_walkthrough, warning=FALSE}
#devtools::install_github("nicebread/BFDA", subdir="package")
#library(BFDA)

# do a sequential design analysis
# scale the beta* prior with the kappa parameter
s1 <- BFDA.sim(expected.ES=0.21, prior=list("stretchedbeta", list(prior.kappa=2)), n.min=50, stepsize=10, n.max=300, B=1000, type="correlation", design="sequential", alternative="greater", cores=4, verbose=FALSE)
s0 <- BFDA.sim(expected.ES=0, prior=list("stretchedbeta", list(prior.kappa=2)), n.min=50, stepsize=10, n.max=300, B=1000, type="correlation", design="sequential", alternative="greater", cores=4, verbose=FALSE)

# if no n.min and n.max is provided in the `BFDA.analyze` function, the values from the simulation are taken
BFDA.analyze(s1, design="sequential", boundary=10)
BFDA.analyze(s0, design="sequential", boundary=10)

BFDA.analyze(s1, design="sequential", boundary=6)
BFDA.analyze(s0, design="sequential", boundary=6)

plot(s1, boundary=c(1/10, 20), n.max=150)
```


# Use case: Apply for a grant with sequential sampling

Granting agencies probably want a fixed sample size in the planning stage in order to quantify the amount of funding. For how much participant renumeration should one apply when using a sequential design?

We suggest to determine the requested sample size using two different design analyses:

1. Compute an open-ended SBF design with the expected effect size to get a distribution of sample sizes at stopping point.
2. Compute the 80% quantile of stopping-ns: `n_q80`
3. Evaluate the characteristics of a *SBF+maxN* design with `n.max = n_q80`. Does it have acceptable false positive and false negative error rates? (If not: tune your boundaries). What is the mean and median expected sample size?
4. Apply for a sample size of `n_q80`.


```{r grant}
# We use the simulation from above. 
# Check the expected sample sizes for an evidential boundary of 10
a1 <- BFDA.analyze(sim.H1, design="sequential", n.min=20, boundary=10)

# --> see 80% quantile in output
a1

# Alternative approach: access stopping-ns directly
n_q80 <- ceiling(quantile(a1$endpoint.n, prob=.80))
n_q80
```

80% of all studies stop earlier than n = `r n_q80`. How does a design with that n.max perform concerning rates of misleading evidence?

```{r grant2}
a2.H1 <- BFDA.analyze(sim.H1, design="sequential", n.min=20, n.max=n_q80, boundary=10)
a2.H0 <- BFDA.analyze(sim.H0, design="sequential", n.min=20, n.max=n_q80, boundary=10)
a2.H1
a2.H0
```

In this design analysis for the *SBF+maxN* design, we can see that, although we apply for `r n_q80` participants in each group, we can expect to stop with `r a2.H1$ASN` participants or less with a 50% chance, if H1 is true. The false negative rate is virtually 0%. That means, if the effect exists in the expected size, this design virtually guarantees to detect it, and we have a good chance to be more efficient.

Under H0, at least half of the studies will have to use the full requested sample of `r n_q80` participants. On average, samples will have a size of n=`r a2.H0$ASN` under H0. We have a `r round(a2.H0$upper.hit.frac*100, 2)`% false positive error rate, and `r round(a2.H0$lower.hit.frac*100, 2)`% of all studies will correctly stop at the H0 boundary. The remaining `r round(a2.H0$n.max.hit.frac*100, 2)`% of all studies will remain inconclusive with respect to the desired evidential threshold of $BF_{10}$ <= 1/10. However, the Bayes factor of these studies can still be interpreted in size and direction. From the output, you can see that the majority of these inconclusive BFs still points into the correct (H0) direction.