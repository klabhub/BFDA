- Compute H0 distribution, include in package (we need this everytime)
- SSD-function: plot H1/H0 scenario side by side

-          In the help file for BFDA.sim in the Arguments section it says that “between-t-test”, “within-t-test”, or “correlation” are excepted. I believe that it should be “t.paired”, “t.between”, or “correlation”.
-          Regarding the BFDA.sim function: is there any reason to set design to “fixed.n” instead of “sequential”, besides saving time, if you indeed plan on using a fixed N design? As long as you set design to “fixed” in the BFDA.analyze function, there is no issue right? If you do use “fixed.n” in the BFDA.sim function, the SSD function won’t work. In other words, even if you really want to use a fixed N design, you should put design to “sequential” in the BFDA.sim function when you want to determine N via the SSD function. Is that correct? Perhaps, it would make sense to add something like this to the SSD function:
if(is.na(var.ns)){stop("sample size is constant, consider setting design to sequential in your BFDA.sim function, even though you intend on using a fixed-N design.")}

-          The boundary argument in the BFDA.sim function can’t be asymmetrical right? So, if you plan on using asymmetrical thresholds (e.g., 10 and 1/6), you should set boundary to the most “stringent” one (10 in this example), right? Or don’t change the default boundary=Inf setting, but then the simulations take more time, correct?


-          I also experienced an issue when drawing expected.ES from a distribution. When, by chance, the expected effect size was very large, the ttest.tstat function (from the BayesFactor package) sometimes returns Inf. I’m not a 100% sure, but this may be considered as hitting the BF threshold, if you specified boundary=Inf in the BFDA.sim function. In any case, when I try the SSD function, it gives the error message “consider setting boundary=Inf in your BFDA.sim function”, though the boundary is already set to Inf.
-          A more “philosophical” remark/question: why is the SSD function “asymmetric”? Correct me if I’m wrong, but now you can specify P(evidence for H1 versus H0|H0 is true) and P(evidence for H1 versus H0|H1 is true). However, you can’t specify P(evidence for H0 versus H1|H0 is true) and P(evidence for H0 versus H1|H1 is true), right? Because of the three-way distinction (with “inconclusive” being the third category), these probabilities are not complementary. If you just base sample size (in a fixed N or SBF maxN design) to reach specific levels of P(evidence for H1 versus H0|H0 is true) and P(evidence for H1 versus H0|H1 is true), you might in some cases end up with a rather low P(evidence for H0 versus H1|H0 is true). In other words, in case H0 is actually true you’re frequently doomed to find inconclusive evidence, because you derived N solely based on and P(evidence for H1 versus H0|H1 is true) and P(evidence for H1 versus H0|H0 is true). Wouldn’t it make sense to replace the alpha and power arguments by generic “error rate” and “success rate” arguments?
-          In the BFDA.sim function, when you set alternative to “directional”, the expected.ES under M1 should be positive, right? Also, in your 2018 PBR paper, you use a normal distribution on effect size. Technically speaking, shouldn’t the distribution be truncated as to only include positive values?
 